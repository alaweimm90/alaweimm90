# ORCHEX: Autonomous Research Validation System

The autonomous research system - rigorous validation of optimization methods through personality-based agents.

## What Is This Directory?

ORCHEX is the **autonomous research validation engine**. It validates optimization methods rigorously using 7 personality-based agents, learns from failures, and continuously improves.

**Quick Facts:**
- ~2,000 lines of Python code
- 7 personality-based research agents
- Self-refutation framework (Popperian falsification)
- 200-question interrogation protocol
- Hall of Failures learning system
- Meta-learning for agent improvement

## Directory Contents

```
ORCHEX/
â”œâ”€â”€ README.md                      â† You are here
â”œâ”€â”€ ORCHEX/                         â† Main ORCHEX module
â”‚   â”œâ”€â”€ __init__.py                â† Agent registry & initialization
â”‚   â”œâ”€â”€ brainstorming/             â† Hypothesis generation
â”‚   â”‚   â”œâ”€â”€ brainstorm_engine.py   â† Generate hypotheses
â”‚   â”‚   â””â”€â”€ [tests]
â”‚   â”œâ”€â”€ experimentation/           â† Experiment design & execution
â”‚   â”‚   â”œâ”€â”€ code_generator.py      â† Generate experiment code
â”‚   â”‚   â”œâ”€â”€ experiment_designer.py â† Design experiments
â”‚   â”‚   â”œâ”€â”€ sandbox_executor.py    â† Safe execution
â”‚   â”‚   â””â”€â”€ [tests]
â”‚   â”œâ”€â”€ learning/                  â† Learning mechanisms
â”‚   â”‚   â”œâ”€â”€ advanced_bandits.py    â† UCB1 multi-armed bandit
â”‚   â”‚   â””â”€â”€ [tests]
â”‚   â”œâ”€â”€ orchestration/             â† Workflow orchestration
â”‚   â”‚   â”œâ”€â”€ workflow_orchestrator.py â† Main orchestrator
â”‚   â”‚   â”œâ”€â”€ intent_classifier.py   â† Intent classification
â”‚   â”‚   â”œâ”€â”€ problem_types.py       â† Problem type definitions
â”‚   â”‚   â””â”€â”€ [tests]
â”‚   â”œâ”€â”€ publication/               â† Paper generation (v0.2+)
â”‚   â”‚   â””â”€â”€ paper_generator.py
â”‚   â”œâ”€â”€ cli.py                     â† Command-line interface
â”‚   â”œâ”€â”€ diagnostics.py             â† Diagnostic tools
â”‚   â”œâ”€â”€ hypothesis_generator.py    â† Hypothesis generation core
â”‚   â”œâ”€â”€ performance_utils.py       â† Performance monitoring
â”‚   â””â”€â”€ protocol.py                â† Core protocols
â”‚
â””â”€â”€ uaro/                          â† Universal solver integration
    â”œâ”€â”€ atlas_integration.py       â† Integration layer
    â”œâ”€â”€ explainability.py          â† Explanation generation
    â”œâ”€â”€ marketplace.py             â† Capability marketplace
    â”œâ”€â”€ reasoning_primitives.py    â† Reasoning tools
    â””â”€â”€ universal_solver.py        â† Universal solver wrapper
```

## The 7 Personality Agents

ORCHEX has 7 unique agents that collaborate in research:

| Agent | Role | Strictness | Superpower |
|-------|------|-----------|-----------|
| ğŸ˜  **Grumpy Refuter** | Self-refutation | 0.9 | Finds flaws ruthlessly |
| ğŸ¤¨ **Skeptical Steve** | Interrogation | 0.8 | Asks 200 tough questions |
| ğŸ¤¦ **Failure Frank** | Learning | 0.7 | Remembers all past mistakes |
| ğŸ˜„ **Optimistic Oliver** | Generation | 0.2 | Dreaming up new ideas |
| ğŸ˜° **Cautious Cathy** | Risk | 0.75 | Identifies all risks |
| ğŸ¤“ **Pedantic Pete** | Review | 0.85 | Rigorous peer reviewer |
| ğŸ‰ **Enthusiastic Emma** | Design | 0.4 | Creative experiment designer |

### How They Work Together

```
Optimistic Oliver         â†’ Generates 5-10 hypotheses
         â†“
Skeptical Steve          â†’ Interrogates with 200 questions
         â†“
Grumpy Refuter           â†’ Attempts self-refutation
         â†“
Enthusiastic Emma        â†’ Designs experiments
         â†“
Pedantic Pete            â†’ Peer review
         â†“
Cautious Cathy           â†’ Risk assessment
         â†“
Failure Frank            â†’ Records in Hall of Failures
         â†“
Result                   â†’ Validated or rejected
```

## Quick Start

### Installation

```bash
# From project root
pip install -e .
pip install -e ".[dev]"
```

### Basic Usage

```python
from ORCHEX.orchestration import WorkflowOrchestrator

# Create orchestrator
orchestrator = WorkflowOrchestrator(topic="optimization")

# Generate hypotheses
hypotheses = orchestrator.generate_hypotheses(count=5)

# Validate with all agents
validation_results = orchestrator.validate_all(hypotheses)

# Learn from results
for hypothesis, result in zip(hypotheses, validation_results):
    if result.is_valid:
        print(f"âœ“ {hypothesis.title}")
    else:
        print(f"âœ— {hypothesis.title}: {result.failure_reason}")
```

### Validating Librex.QAP Methods

```python
from ORCHEX.orchestration import WorkflowOrchestrator
from Librex.QAP.core import OptimizationPipeline

# Generate hypothesis about a new method
hypothesis = orchestrator.hypothesize_method(
    name="quantum_annealing",
    expected_speedup=2.0
)

# Validate with ORCHEX agents
result = orchestrator.validate_hypothesis(hypothesis)

# Record learning
if not result.is_valid:
    hall_of_failures.record(hypothesis, result.reason)
```

## Key Files Explained

### `ORCHEX/__init__.py` â­ (AGENT REGISTRY)

Central initialization file that registers all agents:

**What it does:**
1. Initializes all 7 personality agents
2. Registers capabilities
3. Sets up learning systems
4. Initializes Hall of Failures

**Key Classes:**
- `PersonalityAgent` - Base agent class
- `AgentRegistry` - Agent management
- `AgentCapabilities` - Capability definition

### `orchestration/workflow_orchestrator.py` (MAIN ORCHESTRATOR)

Central orchestration engine that coordinates all agents:

```python
orchestrator = WorkflowOrchestrator(topic="optimization")

# Generate hypotheses
hypotheses = orchestrator.generate_hypotheses()

# Validate with agents
results = orchestrator.validate_all(hypotheses)

# Learn from results
orchestrator.learn_from_validation(results)
```

### `brainstorming/brainstorm_engine.py`

Hypothesis generation system:

**Capabilities:**
- Literature search integration
- Gap identification
- Hypothesis generation (5-10 per topic)
- Novelty scoring

**Usage:**
```python
from ORCHEX.brainstorming import BrainstormEngine

engine = BrainstormEngine()
hypotheses = engine.generate(topic="QAP optimization")
```

### `learning/advanced_bandits.py`

Multi-armed bandit learning system:

**How it works:**
- Treats agents as "arms"
- Uses UCB1 algorithm
- Learns which agents are most effective
- Continuously improves agent selection

**Usage:**
```python
from ORCHEX.learning import AdvancedBandits

bandits = AdvancedBandits()
selected_agents = bandits.select_agents(num=3)  # Best 3 agents
```

### `experimentation/` (v0.2.0)

Experiment design and execution:

- **code_generator.py** - Generate experiment code
- **experiment_designer.py** - Design experiments
- **sandbox_executor.py** - Safe execution environment

(Coming in v0.2.0 release)

### `publication/` (v0.2.0)

Paper generation:

- Generate research papers from findings
- Automated citation management
- Summary generation

(Coming in v0.2.0 release)

## The Validation Process

### Self-Refutation (Popperian Falsification)

Five strategies for testing:

1. **Boundary Testing** - Push to limits
2. **Contradiction Search** - Find logical flaws
3. **Assumption Critique** - Question assumptions
4. **Counterexample Generation** - Find edge cases
5. **Comparative Analysis** - Compare with alternatives

### Interrogation Protocol

Skeptical Steve asks 200+ questions:

```
Question Categories:
â”œâ”€â”€ Methodological (30%)   - Is the method sound?
â”œâ”€â”€ Empirical (40%)        - Do results match?
â”œâ”€â”€ Theoretical (20%)      - Does theory support?
â””â”€â”€ Practical (10%)        - Is it useful?
```

### Integration with Librex.QAP

```python
# Validate an optimization method
from Librex.QAP.core import OptimizationPipeline
from ORCHEX.orchestration import WorkflowOrchestrator

pipeline = OptimizationPipeline(size=20)
result = pipeline.solve(problem, method="fft_laplace")

# ORCHEX validates the result
orchestrator = WorkflowOrchestrator()
validation = orchestrator.validate_optimization_result(result)

if validation.is_sound:
    print("âœ“ Method validated!")
else:
    print(f"Issues found: {validation.issues}")
```

## Extending ORCHEX

### Adding a New Agent

1. **Create agent class**:
   ```python
   class MyCustomAgent(PersonalityAgent):
       def __init__(self):
           super().__init__(name="Custom Agent", strictness=0.5)

       def validate(self, hypothesis):
           # Validation logic
           return ValidationResult(...)
   ```

2. **Register in `ORCHEX/__init__.py`**:
   ```python
   from ORCHEX.agents import MyCustomAgent

   agent_registry = AgentRegistry()
   agent_registry.register(MyCustomAgent())
   ```

3. **Add capabilities**:
   ```python
   agent.add_capability("hypothesis_validation")
   agent.add_capability("risk_assessment")
   ```

4. **Write tests**:
   ```python
   def test_custom_agent():
       agent = MyCustomAgent()
       result = agent.validate(hypothesis)
       assert result.is_valid or not result.is_valid  # Some result
   ```

### Improving Agent Learning

1. **Analyze Hall of Failures**:
   ```python
   from ORCHEX.learning import HallOfFailures

   failures = HallOfFailures()
   patterns = failures.analyze_patterns()
   ```

2. **Update agent behavior**:
   ```python
   agent.update_strategy(patterns)
   agent.improve_heuristics()
   ```

3. **Measure improvement**:
   ```python
   metrics = agent.get_performance_metrics()
   print(f"Accuracy: {metrics['accuracy']}")
   ```

## Running Tests

### All Tests

```bash
# From project root
make test                  # Full test suite

# Or specific to ORCHEX
pytest tests/test_integration.py -v
```

### Key Test Files

**tests/test_integration.py** (206 lines)
- ORCHEX-Librex.QAP integration
- Hypothesis validation
- Agent coordination
- Learning verification

## Real-World Usage Examples

### Scenario 1: Validating a New Optimization Method

```python
from ORCHEX.orchestration import WorkflowOrchestrator

# Create hypothesis about new method
hypothesis = {
    "title": "FFT-Laplace Preconditioning",
    "claim": "Achieves 100x speedup on medium QAP instances",
    "mechanism": "FFT acceleration of Laplacian",
}

# Let ORCHEX validate
orchestrator = WorkflowOrchestrator()
validation = orchestrator.validate(hypothesis)

# Results
print(validation.report())
# Result: âœ“ VALID (with caveats)
# Issues: Not reliable on small instances
```

### Scenario 2: Learning from Past Failures

```python
from ORCHEX.learning import HallOfFailures

failures = HallOfFailures()

# Load past failed hypotheses
past_failures = failures.get_similar(current_hypothesis)

# Learn from them
lessons = failures.extract_lessons(past_failures)

# Apply learning
if "assumption" in lessons:
    print(f"Watch out: {lessons['assumption']}")
```

### Scenario 3: Multi-Agent Collaboration

```python
from ORCHEX.orchestration import WorkflowOrchestrator

orchestrator = WorkflowOrchestrator()

# Run full validation pipeline
result = orchestrator.full_validation(
    hypothesis=hypothesis,
    budget=1000,  # Max iterations
    timeout=3600  # Max seconds
)

# Get report from each agent
for agent_name, agent_result in result.agent_reports.items():
    print(f"{agent_name}: {agent_result.verdict}")
```

## Architecture Highlights

### Agent Coordination

```
WorkflowOrchestrator
â”œâ”€â”€ Initialize Agents
â”œâ”€â”€ For each hypothesis:
â”‚   â”œâ”€â”€ Optimistic Oliver: Generate ideas
â”‚   â”œâ”€â”€ Skeptical Steve: Interrogate
â”‚   â”œâ”€â”€ Grumpy Refuter: Try to refute
â”‚   â”œâ”€â”€ Enthusiastic Emma: Design test
â”‚   â”œâ”€â”€ Pedantic Pete: Review
â”‚   â”œâ”€â”€ Cautious Cathy: Assess risks
â”‚   â””â”€â”€ Failure Frank: Learn lessons
â””â”€â”€ Return comprehensive validation
```

### Learning Loop

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  New Hypothesis         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Validate with Agents   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Record Failure/Success â”‚
â”‚  (Hall of Failures)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Update Agent Learning  â”‚
â”‚  (Meta-learning)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
     Next iteration improved!
```

## Troubleshooting

### Agent not responding?
```python
from ORCHEX.orchestration import WorkflowOrchestrator

orch = WorkflowOrchestrator()
status = orch.check_agent_status()
for agent, is_active in status.items():
    print(f"{agent}: {'âœ“' if is_active else 'âœ—'}")
```

### Validation taking too long?
```python
# Use time limits
result = orchestrator.validate(hypothesis, timeout=300)
```

### Want to see agent reasoning?
```python
# Enable verbose logging
orchestrator.enable_verbose_logging()
result = orchestrator.validate(hypothesis)
# Now you'll see detailed agent reasoning
```

## Contributing

We welcome contributions! See `CONTRIBUTING.md` for:
- How to add new agents
- Testing requirements
- Documentation standards

## Related Documentation

- **PROJECT.md** - Complete project overview
- **STRUCTURE.md** - Directory structure guide
- **DEVELOPMENT.md** - Development workflow
- **CONTRIBUTING.md** - Contribution guidelines
- **.archive/docs/ORCHEX/** - Historical documentation

## Key Concepts

### Hypothesis
A testable claim about optimization methods

### Validation Result
The output of agent validation with verdicts and reasoning

### Hall of Failures
Database of past failures to learn from

### Agent Strictness
How harsh agents are in validation (0.0-1.0)

## Performance

| Agent | Speed | Thoroughness | Notes |
|-------|-------|--------------|-------|
| Optimistic Oliver | Fast | Low | Generates ideas |
| Skeptical Steve | Medium | High | 200 questions |
| Grumpy Refuter | Medium | Very High | Tries hard to break |
| Enthusiastic Emma | Medium | Medium | Creative testing |
| Pedantic Pete | Slow | Very High | Thorough review |
| Cautious Cathy | Fast | High | Risk-focused |
| Failure Frank | Fast | Medium | Lookup-based |

## Status & Roadmap

**Current (v0.1.0):**
- âœ… All 7 personality agents
- âœ… Hypothesis generation
- âœ… Validation framework
- âœ… Hall of Failures
- âœ… Meta-learning basics

**Next (v0.2.0):**
- [ ] Full experimentation (code gen, sandbox)
- [ ] Paper generation
- [ ] Advanced learning strategies
- [ ] API server

## Authors & Citation

**Author:** Meshal Alawein

**Citation:**
```bibtex
@software{atlas_2024,
  title = {ORCHEX: Autonomous Research Validation System},
  author = {Alawein, Meshal},
  year = {2024},
  url = {https://github.com/AlaweinOS/AlaweinOS/tree/main/Librex.QAP-new/ORCHEX},
  note = {7 personality-based research agents with self-improvement}
}
```

## License

MIT License - See `LICENSE` in project root

---

**Happy researching!** ğŸš€

Questions? Check `PROJECT.md` or `STRUCTURE.md` for more information.

Last Updated: November 2024
