{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "source": "# TODO: Continue with data cleaning and preprocessing steps\n# Still need to implement:\n# 1. Missing value imputation strategies\n# 2. Outlier removal/treatment  \n# 3. Feature scaling comparison (StandardScaler vs RobustScaler)\n# 4. Feature selection methods\n#\n# RESEARCH: Look up best practices for materials data preprocessing\n# Question: Should we remove outliers or just flag them?\n# \n# INCOMPLETE - need to finish missing value handling\nprint(\"ðŸš§ Preprocessing section partially complete\")\nprint(\"Next: Add imputation and scaling examples\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Advanced preprocessing techniques for materials data\nfrom sklearn.preprocessing import MinMaxScaler, RobustScaler\nfrom sklearn.feature_selection import VarianceThreshold, SelectKBest, f_regression\nfrom scipy import stats\n\n# Create extended materials dataset with realistic noise and missing values\ndef create_noisy_materials_dataset():\n    \"\"\"Create a more realistic materials dataset with preprocessing challenges.\"\"\"\n    \n    # Base materials data with some missing values and outliers\n    materials_data = [\n        # Format: [name, formula, space_group, a, b, c, bandgap, formation_energy, class]\n        [\"Silicon\", \"Si\", \"Fd-3m\", 5.431, 5.431, 5.431, 1.12, -5.45, \"Semiconductor\"],\n        [\"GaAs\", \"GaAs\", \"F-43m\", 5.653, 5.653, 5.653, 1.42, -0.74, \"Semiconductor\"],\n        [\"MoS2\", \"MoS2\", \"P63/mmc\", 3.16, 3.16, 12.3, 1.8, -1.23, \"2D Material\"],\n        [\"WSe2\", \"WSe2\", \"P63/mmc\", 3.28, 3.28, 12.96, 1.6, -1.45, \"2D Material\"],\n        [\"Graphene\", \"C\", \"P6/mmm\", 2.46, 2.46, 6.7, 0.0, 0.0, \"2D Material\"],\n        [\"hBN\", \"BN\", \"P63/mmc\", 2.50, 2.50, 6.66, 5.9, -2.51, \"Insulator\"],\n        [\"TiO2\", \"TiO2\", \"P42/mnm\", 4.594, 4.594, 2.959, 3.2, -9.45, \"Insulator\"],\n        [\"ZnO\", \"ZnO\", \"P63mc\", 3.25, 3.25, 5.207, 3.37, -3.48, \"Semiconductor\"],\n        [\"CdTe\", \"CdTe\", \"F-43m\", 6.482, 6.482, 6.482, 1.5, -0.92, \"Semiconductor\"],\n        [\"InP\", \"InP\", \"F-43m\", 5.869, 5.869, 5.869, 1.34, -0.88, \"Semiconductor\"],\n        [\"GaN\", \"GaN\", \"P63mc\", 3.189, 3.189, 5.185, 3.4, -1.09, \"Semiconductor\"],\n        [\"AlN\", \"AlN\", \"P63mc\", 3.112, 3.112, 4.982, 6.2, -3.29, \"Insulator\"],\n        [\"SiC\", \"SiC\", \"F-43m\", 4.359, 4.359, 4.359, 2.36, -0.73, \"Semiconductor\"],\n        [\"SnO2\", \"SnO2\", \"P42/mnm\", 4.737, 4.737, 3.186, 3.6, -5.81, \"Semiconductor\"],\n        [\"Cu2O\", \"Cu2O\", \"Pn-3m\", 4.27, 4.27, 4.27, 2.17, -1.68, \"Semiconductor\"],\n        [\"Diamond\", \"C\", \"Fd-3m\", 3.567, 3.567, 3.567, 5.5, 0.02, \"Insulator\"],\n        [\"BP\", \"BP\", \"Pnma\", 3.31, 10.48, 4.54, 2.0, -1.19, \"Semiconductor\"],\n        [\"WS2\", \"WS2\", \"P63/mmc\", 3.155, 3.155, 12.323, 1.35, -1.48, \"2D Material\"],\n        [\"NaCl\", \"NaCl\", \"Fm-3m\", 5.64, 5.64, 5.64, 8.5, -4.11, \"Insulator\"],\n        [\"MgO\", \"MgO\", \"Fm-3m\", 4.212, 4.212, 4.212, 7.8, -6.08, \"Insulator\"]\n    ]\n    \n    # Convert to DataFrame\n    columns = ['Material', 'Formula', 'Space_Group', 'a', 'b', 'c', \n               'Bandgap_eV', 'Formation_Energy_eV', 'Class']\n    df = pd.DataFrame(materials_data, columns=columns)\n    \n    # Add computed features\n    df['Volume'] = df['a'] * df['b'] * df['c']\n    df['Average_Lattice'] = (df['a'] + df['b'] + df['c']) / 3\n    df['Is_Cubic'] = ((df['a'] - df['b']).abs() < 0.01) & ((df['b'] - df['c']).abs() < 0.01)\n    df['Anisotropy'] = (df[['a', 'b', 'c']].max(axis=1) - df[['a', 'b', 'c']].min(axis=1)) / df['Average_Lattice']\n    \n    # Add some measurement noise (realistic experimental uncertainty)\n    np.random.seed(42)\n    noise_factors = {\n        'Bandgap_eV': 0.05,       # Â±5% uncertainty\n        'Formation_Energy_eV': 0.1, # Â±10% uncertainty\n        'a': 0.01, 'b': 0.01, 'c': 0.01  # Â±1% lattice uncertainty\n    }\n    \n    for col, noise_level in noise_factors.items():\n        if col in df.columns:\n            noise = np.random.normal(0, df[col].abs() * noise_level)\n            df[col] = df[col] + noise\n    \n    # Introduce some missing values (realistic for experimental datasets)\n    missing_indices = np.random.choice(df.index, size=3, replace=False)\n    df.loc[missing_indices[0], 'Formation_Energy_eV'] = np.nan\n    df.loc[missing_indices[1], 'c'] = np.nan\n    df.loc[missing_indices[2], 'Anisotropy'] = np.nan\n    \n    # Add one outlier (measurement error)\n    outlier_idx = np.random.choice(df.index)\n    df.loc[outlier_idx, 'Bandgap_eV'] = 15.0  # Unrealistic value\n    \n    return df\n\n# Load and examine the noisy dataset\nprint(\"ðŸ”§ Materials Dataset with Preprocessing Challenges\")\nprint(\"=\" * 55)\n\ndf_raw = create_noisy_materials_dataset()\n\nprint(f\"Raw dataset shape: {df_raw.shape}\")\nprint(f\"Materials: {len(df_raw)}\")\n\n# Check for missing values\nmissing_summary = df_raw.isnull().sum()\nmissing_cols = missing_summary[missing_summary > 0]\n\nprint(f\"\\nâŒ Missing Values Found:\")\nfor col, count in missing_cols.items():\n    print(f\"  {col}: {count} missing ({count/len(df_raw)*100:.1f}%)\")\n\n# Check for outliers using Z-score\nnumeric_cols = df_raw.select_dtypes(include=[np.number]).columns.tolist()\nprint(f\"\\nðŸ“Š Outlier Detection (Z-score > 3):\")\n\noutliers_found = False\nfor col in numeric_cols:\n    if col in df_raw.columns:\n        z_scores = np.abs(stats.zscore(df_raw[col].dropna()))\n        outlier_mask = z_scores > 3\n        if outlier_mask.any():\n            outlier_count = outlier_mask.sum()\n            print(f\"  {col}: {outlier_count} outliers\")\n            outliers_found = True\n\nif not outliers_found:\n    print(\"  No major outliers detected\")\n\n# Display sample of raw data\nprint(f\"\\nðŸ“‹ Raw Data Sample:\")\nprint(df_raw[['Material', 'Formula', 'Bandgap_eV', 'Formation_Energy_eV', 'Volume']].head(8).round(3))",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# 2. Preprocessing - Data Preparation for Materials ML\n\nData preprocessing is essential for successful machine learning in materials science. Raw experimental and computational data often requires cleaning, transformation, and feature scaling to achieve optimal model performance.\n\n## Key Preprocessing Steps\n\n**Data cleaning:**\n- Handle missing values and outliers\n- Remove duplicate entries\n- Correct measurement units and inconsistencies\n\n**Feature scaling:**\n- Standardization: zero mean, unit variance\n- Normalization: scale to [0,1] range\n- Robust scaling: median and IQR-based\n\n**Feature selection:**\n- Correlation-based filtering\n- Variance-based filtering\n- Statistical significance testing\n\nThis section demonstrates essential preprocessing techniques for materials datasets.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_cell"
   },
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# ðŸ“¦ Install Scikit-learn (Colab only)\n",
    "# ==========================\n",
    "!pip install scikit-learn pandas matplotlib numpy seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "intro_cell"
   },
   "source": [
    "# Classical Machine Learning with Scikit-learn: A Beginner's Guide\n",
    "\n",
    "This notebook introduces fundamental concepts in classical machine learning using Scikit-learn, specifically for materials science applications. We will explore data loading, preprocessing, classification, regression, PCA analysis, and high-throughput screening approaches.\n",
    "\n",
    "**Learning Path**: Data Loading â†’ Preprocessing â†’ Classification â†’ Regression â†’ PCA Analysis â†’ High-throughput Screening\n",
    "\n",
    "Let's start by setting up our machine learning environment for materials informatics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup_cell"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries for classical ML and materials science\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.svm import SVR, SVC\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, accuracy_score, classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(f\"Scikit-learn ready for materials informatics!\")\n",
    "print(f\"NumPy: {np.__version__}, Pandas: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "concept_1_theory"
   },
   "source": [
    "# âœ… 1. Data Loading - Materials Dataset Handling\n",
    "\n",
    "The first step in any materials informatics project is loading and understanding your dataset. Materials data comes in various formats and often requires careful preprocessing to extract meaningful features.\n",
    "\n",
    "## Common Materials Data Sources\n",
    "\n",
    "- **Experimental databases**: ICSD, NIST, Materials Project\n",
    "- **Computational databases**: AFLOW, OQMD, C2DB\n",
    "- **Literature mining**: Automated extraction from papers\n",
    "- **High-throughput calculations**: DFT, MD simulations\n",
    "\n",
    "## Key Considerations\n",
    "\n",
    "- **Data quality**: Missing values, outliers, measurement errors\n",
    "- **Feature engineering**: Converting chemical formulas to descriptors\n",
    "- **Target variables**: Property of interest (bandgap, formation energy, etc.)\n",
    "- **Data imbalance**: Uneven representation of materials classes\n",
    "\n",
    "This section demonstrates loading and exploring materials datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "concept_1_code"
   },
   "outputs": [],
   "source": [
    "# Create comprehensive materials dataset for demonstration\n",
    "def create_materials_dataset():\n",
    "    \"\"\"Create a realistic materials dataset for ML demonstrations.\"\"\"\n",
    "    \n",
    "    # Material systems and their properties\n",
    "    materials_data = [\n",
    "        # Format: [name, formula, space_group, a, b, c, bandgap, formation_energy, class]\n",
    "        [\"Silicon\", \"Si\", \"Fd-3m\", 5.431, 5.431, 5.431, 1.12, -5.45, \"Semiconductor\"],\n",
    "        [\"Gallium Arsenide\", \"GaAs\", \"F-43m\", 5.653, 5.653, 5.653, 1.42, -0.74, \"Semiconductor\"],\n",
    "        [\"Molybdenum Disulfide\", \"MoS2\", \"P63/mmc\", 3.16, 3.16, 12.3, 1.8, -1.23, \"2D Material\"],\n",
    "        [\"Tungsten Diselenide\", \"WSe2\", \"P63/mmc\", 3.28, 3.28, 12.96, 1.6, -1.45, \"2D Material\"],\n",
    "        [\"Graphene\", \"C\", \"P6/mmm\", 2.46, 2.46, 6.7, 0.0, 0.0, \"2D Material\"],\n",
    "        [\"Hexagonal Boron Nitride\", \"BN\", \"P63/mmc\", 2.50, 2.50, 6.66, 5.9, -2.51, \"Insulator\"],\n",
    "        [\"Titanium Dioxide\", \"TiO2\", \"P42/mnm\", 4.594, 4.594, 2.959, 3.2, -9.45, \"Insulator\"],\n",
    "        [\"Zinc Oxide\", \"ZnO\", \"P63mc\", 3.25, 3.25, 5.207, 3.37, -3.48, \"Semiconductor\"],\n",
    "        [\"Cadmium Telluride\", \"CdTe\", \"F-43m\", 6.482, 6.482, 6.482, 1.5, -0.92, \"Semiconductor\"],\n",
    "        [\"Indium Phosphide\", \"InP\", \"F-43m\", 5.869, 5.869, 5.869, 1.34, -0.88, \"Semiconductor\"],\n",
    "        [\"Gallium Nitride\", \"GaN\", \"P63mc\", 3.189, 3.189, 5.185, 3.4, -1.09, \"Semiconductor\"],\n",
    "        [\"Aluminum Nitride\", \"AlN\", \"P63mc\", 3.112, 3.112, 4.982, 6.2, -3.29, \"Insulator\"],\n",
    "        [\"Silicon Carbide\", \"SiC\", \"F-43m\", 4.359, 4.359, 4.359, 2.36, -0.73, \"Semiconductor\"],\n",
    "        [\"Tin Dioxide\", \"SnO2\", \"P42/mnm\", 4.737, 4.737, 3.186, 3.6, -5.81, \"Semiconductor\"],\n",
    "        [\"Copper Oxide\", \"Cu2O\", \"Pn-3m\", 4.27, 4.27, 4.27, 2.17, -1.68, \"Semiconductor\"]\n",
    "    ]\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    columns = ['Material', 'Formula', 'Space_Group', 'a', 'b', 'c', \n",
    "               'Bandgap_eV', 'Formation_Energy_eV', 'Class']\n",
    "    df = pd.DataFrame(materials_data, columns=columns)\n",
    "    \n",
    "    # Add computed features\n",
    "    df['Volume'] = df['a'] * df['b'] * df['c']\n",
    "    df['Average_Lattice'] = (df['a'] + df['b'] + df['c']) / 3\n",
    "    df['Is_Cubic'] = ((df['a'] - df['b']).abs() < 0.01) & ((df['b'] - df['c']).abs() < 0.01)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Load the materials dataset\n",
    "print(\"ðŸ”¬ Loading Materials Dataset\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "df = create_materials_dataset()\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(\"\\nðŸ“Š First 5 materials:\")\n",
    "print(df.head())\n",
    "\n",
    "# Dataset overview\n",
    "print(\"\\nðŸ“‹ Dataset Information:\")\n",
    "print(f\"Total materials: {len(df)}\")\n",
    "print(f\"Material classes: {df['Class'].unique()}\")\n",
    "print(f\"Class distribution:\")\n",
    "print(df['Class'].value_counts())\n",
    "\n",
    "# Statistical summary\n",
    "print(\"\\nðŸ“ˆ Property Statistics:\")\n",
    "numeric_cols = ['Bandgap_eV', 'Formation_Energy_eV', 'Volume', 'Average_Lattice']\n",
    "print(df[numeric_cols].describe().round(2))\n",
    "\n",
    "# Data quality check\n",
    "print(\"\\nðŸ” Data Quality Check:\")\n",
    "print(f\"Missing values: {df.isnull().sum().sum()}\")\n",
    "print(f\"Duplicate entries: {df.duplicated().sum()}\")\n",
    "print(f\"Unique space groups: {df['Space_Group'].nunique()}\")"
   ]
  }
 ]
}